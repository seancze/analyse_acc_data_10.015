{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Used for loading csv files into excel\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_dict(file_names):\n",
    "    '''\n",
    "    Input: Requires a list of .csv files\n",
    "    Output:\n",
    "    - A dictionary with values sorted according to the train trip\n",
    "    - file_names excluding '.csv'\n",
    "    \n",
    "    '''\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    # Retrieve file_names\n",
    "    file_names = ''.join(all_files).split('.csv')[:-1]\n",
    "\n",
    "\n",
    "    for name in file_names:\n",
    "\n",
    "    # If name of file as a digit, find index of digit\n",
    "        if hasNumbers(name):\n",
    "\n",
    "    # Find the index of the digit\n",
    "            idx = [char.isdigit() for char in name].index(True)\n",
    "\n",
    "    # Split by the index and store the front end as the key\n",
    "    # Note: '-1' is to exclude the whitespace as well\n",
    "            key = name[:idx-1]\n",
    "            if key in d:\n",
    "                d[key].append(name)\n",
    "            else:\n",
    "                d[key] = [name]\n",
    "        else:\n",
    "            if name in d:\n",
    "                d[name].append(name)\n",
    "            else:\n",
    "                d[name] = [name]\n",
    "\n",
    "    \n",
    "    return d, file_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_excel(d, wb, acc_header):\n",
    "    '''\n",
    "    Input: A dictionary of .csv file names, Excel workbook, Header of acceleration values to calculate average acceleration values\n",
    "    Output: Data imported into excel workbook\n",
    "    '''\n",
    "\n",
    "\n",
    "    # For each key in dictionary\n",
    "    for i, key in enumerate(d):\n",
    "\n",
    "    #     Convert the respective files into a list of df\n",
    "        df_list = [pd.read_csv(f'{file}.csv') for file in d[key]]\n",
    "\n",
    "    #     Concatenate the dfs into 1\n",
    "        concat_df = pd.concat(df_list, axis = 1)\n",
    "\n",
    "    #     Create a new column: Average of all acceleration data\n",
    "        concat_df['Average Y'] = concat_df[acc_header].mean(axis=1)\n",
    "\n",
    "    #     Store key as title of file\n",
    "        title = key\n",
    "\n",
    "    #     Create ws with the title == key of dictionary\n",
    "        ws = wb.create_sheet(index=i, title=title)\n",
    "\n",
    "    #     Import the df into the excel sheet\n",
    "        for r in dataframe_to_rows(concat_df, index=False, header=True):\n",
    "            ws.append(r)\n",
    "\n",
    "    try:\n",
    "        wb.save(f'{excel_wb_name}.xlsx')\n",
    "        print(f\"Excel workbook created at {user_dir}\")\n",
    "    except:\n",
    "        print('''\n",
    "        Excel file failed to create. \n",
    "        Please check that the name given does not contain the following special characters:\n",
    "        / \\ : * ? \" < > | ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new Excel workbook\n",
    "wb = openpyxl.Workbook()\n",
    "# Just to remove the spare sheet\n",
    "wb.remove(wb.active)\n",
    "\n",
    "# Retrieve directory containing all .csv files\n",
    "user_dir = input(\"Please input the path to the directory containing all the .csv files: \")\n",
    "path = 'c:\\\\'\n",
    "extension = 'csv'\n",
    "os.chdir(user_dir)\n",
    "all_files = glob.glob('*.{}'.format(extension))\n",
    "d, file_names = sorted_dict(all_files)\n",
    "\n",
    "# Ask User for header of timestamp, of acc values\n",
    "t_header = input(\"Please input the name of the header for the timestamp column (CASE-SENSITIVE): \")\n",
    "acc_header = input(\"Please input the name of the header for the acceleration column (CASE-SENSITIVE): \")\n",
    "excel_wb_name = input(\"An excel workbook will be created. Please input your preferred name (CASE-SENSITIVE): \")\n",
    "print(\"File is running...\")\n",
    "\n",
    "try:\n",
    "    csv_to_excel(d, wb, acc_header)\n",
    "except:\n",
    "    print(\"Please ensure that the folder only contains .csv files for the accelerometer readings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "Reading Excel file...''')\n",
    "\n",
    "acceleration_data = pd.read_excel(f'{excel_wb_name}.xlsx', sheet_name=None, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_headers(df):\n",
    "    \n",
    "# Format headers as long as the first row is not a numerical value\n",
    "# Note: Headers are not considered as the first row\n",
    "# Note: '.item()' is to convert numpy types to native Python types\n",
    "    try:\n",
    "        if type(df.iloc[0, 0].item()) == float:\n",
    "            pass\n",
    "    except:\n",
    "        header = df.iloc[0]\n",
    "        df = df[1:]\n",
    "        df.columns = header\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_speed(velocity):\n",
    "    '''\n",
    "    Takes in the calculated velocity.\n",
    "    Returns a list of speed at each timestamp\n",
    "    '''\n",
    "\n",
    "def get_max_v(acc, method = 's'):\n",
    "    '''\n",
    "    Returns a float by integrating acceleration via Simpson's Rule\n",
    "    '''\n",
    "    acc = list(acc)\n",
    "    cleaned_acc = [el for el in acc if str(el) != 'nan']\n",
    "    \n",
    "    d_v = []\n",
    "    accum_v = []\n",
    "    max_v = 0\n",
    "    \n",
    "    if method.lower() == 's':\n",
    "        for i in range(0, len(cleaned_acc)-2, 2):\n",
    "        #     Simpson's Rule\n",
    "            velocity = ((0.02)/3) * (cleaned_acc[i] + 4 * cleaned_acc[i+1] + cleaned_acc[i+2])\n",
    "            d_v.append(velocity)\n",
    "            \n",
    "#         To obtain accumulated velocity (NOT SPEED) at each timestamp NOTE: REPEATED CODE\n",
    "# Should be velocity so that if change in velocity is negative, then the velocity will decrease accordingly\n",
    "# I guess technically, can be speed also coz if change in velocity is negative, it means object is slowing down\n",
    "            if i == 0:\n",
    "                accum_v.append(velocity)\n",
    "            else:\n",
    "                accum_v.append(velocity + accum_v[-1]) \n",
    "\n",
    "#             accum_v.append(sum(d_v))\n",
    "            \n",
    "#         Just to speed up the loop so that I don't always have to sum up the array and check with max_v\n",
    "            if i < len(cleaned_acc)*0.2:\n",
    "                continue\n",
    "\n",
    "            if sum(d_v) > max_v:\n",
    "                max_v = sum(d_v)\n",
    "                \n",
    "    else:\n",
    "        for i in range(0, len(cleaned_acc)-1):\n",
    "            velocity = (1/2) * (cleaned_acc[i+1]+cleaned_acc[i]) * 0.02\n",
    "            d_v.append(velocity)\n",
    "            \n",
    "#         To obtain accumulated velocity (NOT SPEED) at each timestamp NOTE: REPEATED CODE\n",
    "            if i == 0:\n",
    "                accum_v.append(velocity)\n",
    "            else:\n",
    "                accum_v.append(velocity + accum_v[-1]) \n",
    "            \n",
    "#         Just to speed up the loop so that I don't always have to sum up the array and check with max_v\n",
    "            if i < len(cleaned_acc)*0.2:\n",
    "                continue\n",
    "\n",
    "            if sum(d_v) > max_v:\n",
    "                max_v = sum(d_v)\n",
    "            \n",
    "            \n",
    "    return max_v, accum_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCHIVED\n",
    "# def get_total_dist(accum_v, method = 's'):\n",
    "#     total_dist = 0\n",
    "#     for i in accum_v:\n",
    "            \n",
    "# #         In Sinusoidal method, the time-interval is over 2 data points for it is for a parabola\n",
    "#             if method.lower() == 's': \n",
    "#                 total_dist += 0.04 * abs(i)\n",
    "# #       In Trapezoidal method, the time-interval is over 1 data point\n",
    "#             else:\n",
    "#                 total_dist += 0.02 * abs(i)\n",
    "            \n",
    "#     return total_dist\n",
    "\n",
    "def get_total_dist(accum_v, method = 's'):\n",
    "    \n",
    "#     To make sure that even if velocity is negative, we still add \n",
    "# Note: Should NOT be possible for velocity to be negative for the train does NOT move backwards!\n",
    "    speed_arr = np.abs(np.array(accum_v))\n",
    "    \n",
    "#     In Sinusoidal method, the time-interval is over 2 data points for it is for a parabola\n",
    "    if method == 's':\n",
    "        total_dist = sum(np.multiply(speed_arr, 0.04))\n",
    "        \n",
    "#     In Trapezoidal method, the time-interval is over 1 data point\n",
    "    else:\n",
    "        total_dist = sum(np.multiply(speed_arr, 0.02))\n",
    "        \n",
    "    return total_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(mypath):\n",
    "    '''Creates a directory. equivalent to using mkdir -p on the command line'''\n",
    "\n",
    "    from errno import EEXIST\n",
    "    from os import makedirs,path\n",
    "\n",
    "    try:\n",
    "        makedirs(mypath)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == EEXIST and path.isdir(mypath):\n",
    "            pass\n",
    "        else: raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_x_and_y_axes(df):\n",
    "    '''\n",
    "    Returns the x and y axes for the plotting of graph\n",
    "    x-axis: Time\n",
    "    y-axis: Average Acceleration\n",
    "    '''\n",
    "    \n",
    "    try: \n",
    "    # Remove all rows where all values are blank then Retrieve the last value    \n",
    "        last_value_of_t = df[t_header].dropna(how='all').iloc[-1]\n",
    "        t = df[t_header].dropna(how='all')\n",
    "\n",
    "    # If there's only 1 \"Timestamp\" in the excel sheet, then our x-axis will just equal to it. 'pass' because values assigned to t already is correct\n",
    "        if type(last_value_of_t) == float:\n",
    "            pass\n",
    "        else:\n",
    "    # Retrieve index of time that is not 'NaN'. This is equivalent to retrieving maximum time (I.e. Most number of rows)\n",
    "            time_formatted = [i for i, el in enumerate(list(t.iloc[-1])) if not math.isnan(el)]\n",
    "            idx = time_formatted[0] # This works because there should only be 1 value that is 'NaN' \n",
    "    # If there is 2 or more, this means that all the time end at the same row / time which is highly unlikely. Even if it does happen, I will still be retrieving the idx of the max t\n",
    "\n",
    "\n",
    "    # t = Col with most number of rows\n",
    "            t = df[t_header].dropna(how='all').iloc[:, idx]\n",
    "    except:\n",
    "        print(\"Please ensure that there is no column labelled 'Timestamp' that is empty. If so, please remove the header, 'Timestamp'\")\n",
    "        \n",
    "\n",
    "# Note: This only works if t.iloc[-1] is a number and not an error like 'nan'\n",
    "    last_idx = t[t == t.iloc[-1]].index[0]\n",
    "    acc_y = df[\"Average Y\"].dropna(how='all').iloc[:last_idx]\n",
    "    \n",
    "# Find the idx of the first value of acc_y. Ensures that if first value of t happens to be blank for whatever reason, it will not be picked.\n",
    "    first_float_idx = next((i for i, x in enumerate(acc_y) if isinstance(x, float)), None)\n",
    "    start_idx = next((i for i, x in enumerate(acc_y) if (x-acc_y.iloc[first_float_idx]) > 0.01), None)\n",
    "    \n",
    "# Re-assign both variables to ensure that num rows of acc_y correspond to t\n",
    "    acc_y = df[\"Average Y\"].iloc[start_idx:last_idx]\n",
    "    t = t.iloc[start_idx:last_idx]\n",
    "#   acc_y_calibrated = df[\"Average Y calibrated\"]\n",
    "\n",
    "    return t, acc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df, title, method = 's'):\n",
    "    \n",
    "    df = format_headers(df)\n",
    "    \n",
    "    t, acc_y = retrieve_x_and_y_axes(df)\n",
    "\n",
    "# Obtain an array of negative values\n",
    "    negative_value_list = [value for value in acc_y if value < 0]\n",
    "\n",
    "# Retrieve the index of the first negative value\n",
    "    negative_value = acc_y[acc_y == negative_value_list[0]].index[0]\n",
    "    \n",
    "# If the length from start to negative_value is less than 10% of all data points, retrieve next negative value\n",
    "# This ensures that negative values that appear early on does not cause threshold to anomalously be placed incorrectly\n",
    "    until_negative_list = acc_y[:negative_value-1]\n",
    "    i = 1\n",
    "    while len(until_negative_list) < (len(t) * 0.1):\n",
    "        negative_value = acc_y[acc_y == negative_value_list[i]].index[0]\n",
    "        until_negative_list = acc_y[:negative_value-1]\n",
    "        i += 1\n",
    "    cut_off_t = t[negative_value-1] # Same as: t[len(until_negative_list)]\n",
    "    \n",
    "#     print(len(until_negative_list), i)\n",
    "    \n",
    "    acc_y_mean = sum(until_negative_list / len(until_negative_list))\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "\n",
    "#     Uncalibrated\n",
    "    axes.set_xlabel('time (s)')\n",
    "    axes.set_ylabel('Acceleration_y (ms^-1)', color='tab:blue')\n",
    "    axes.plot(t,acc_y,color=\"red\", lw=2, ls='-')\n",
    "    axes.axvline(cut_off_t, 0, 1, label='Cut-off for acceleration')\n",
    "    axes.axhline(0, color='black')\n",
    "    axes.legend()\n",
    "    axes.title.set_text(title)\n",
    "    \n",
    "#     Calibrated Graph\n",
    "#     axes[1].set_xlabel('time (s)')\n",
    "#     axes[1].set_ylabel('Acceleration_y (ms^-1)', color='tab:blue')\n",
    "#     axes[1].plot(t,acc_y_calibrated,color=\"red\", lw=2, ls='-')\n",
    "#     axes[1].axvline(t[negative_value-1], 0, 1, label='Cut-off for acceleration')\n",
    "#     axes[1].axhline(0, color='black')\n",
    "#     axes[1].legend()\n",
    "#     axes[1].title.set_text('Calibrated ' + title)\n",
    "\n",
    "\n",
    "#     Calculate values\n",
    "\n",
    "    max_v, accum_v = get_max_v(acc_y, method)\n",
    "    total_dist = get_total_dist(accum_v, method)\n",
    "    \n",
    "    try:\n",
    "#   Retrieve start station\n",
    "        station_start = title.split(' to ')[0]\n",
    "#   Retrieve end station\n",
    "        station_end = title.split(' to ')[1]\n",
    "    except:\n",
    "        print('''\n",
    "        Ensure that the name of your excel sheet is labelled <station_start> to <station_end>\n",
    "        The ' to ' in between both station names is important!\n",
    "        ''')\n",
    "\n",
    "    total_time_taken = t.iloc[-1]\n",
    "#     We cannot simply retrieve last value of t as the first value of t is NOT 0\n",
    "    total_time_offset = t.iloc[-1] - t.iloc[0]\n",
    "    data = [station_start, station_end, total_dist, total_time_taken, total_time_offset, max_v, acc_y_mean, cut_off_t, method]\n",
    "    print(f'''\n",
    "    'Station_start', 'Station_end', 'Total Distance (m)', 'Total Time Taken (s)', 'Time Taken w Offset (s)', 'Max Velocity (ms^-1)', 'Mean Acceleration (ms^-2)', 'Cut-off t (s)'\n",
    "    {station_start}, {station_end}, {total_dist}, {total_time_taken}, {total_time_offset} {acc_y_mean}, {cut_off_t}\n",
    "    Method used: {method}, where 's' = Sinusoidal and 't' = Trapezoidal\n",
    "    ''')\n",
    "    \n",
    "#     Save charts into the directory 'Graph' under the file_name labelled 'title'\n",
    "    output_dir = \"Graphs\"\n",
    "    mkdir_p(output_dir)\n",
    "    plt.savefig(f'{output_dir}/{title}.png')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {'title': ['Station_start', 'Station_end', 'Total Distance', 'Total Time Taken (s)', 'Total Time w Offset (s)', 'Max Velocity (ms^-1)', 'Mean Acceleration', 'Cut-off t (s)', 'Method Used']}\n",
    "for i, title in enumerate(acceleration_data):\n",
    "    all_data[i] = plot_graph(acceleration_data[title], title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = input(\"Would you like to output to a .csv or .txt file? Type 'csv' or 'txt': \").lower()\n",
    "\n",
    "# Ensure input is either 'csv' or 'txt'\n",
    "while True:\n",
    "#     If file_type is neither 'csv' nor 'txt' > Ask for input again\n",
    "    if file_type != 'csv' and file_type != 'txt':\n",
    "        print(file_type.lower())\n",
    "        file_type = input(\"Invalid input. Please input 'csv' or 'txt' to output data to a .csv or .txt file respectively: \")\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "        \n",
    "file_name = input(\"Please input the name of your file: \")\n",
    "\n",
    "\n",
    "if file_type == 'csv':\n",
    "    f = file_name + '.' + file_type\n",
    "    \n",
    "    with open(f, 'w', newline='') as file:\n",
    "        for i in all_data:\n",
    "            file.write(', '.join(str(el) for el in all_data[i]))\n",
    "            file.write('\\n')\n",
    "else:\n",
    "    f = file_name + '.' + file_type\n",
    "    with open(f, 'w', newline='') as file:\n",
    "        for i in all_data:\n",
    "            file.write(', '.join(str(el) for el in all_data[i]))\n",
    "            file.write('\\n')\n",
    "\n",
    "print(f'''\n",
    "File completed! :)\n",
    "Total Time Taken: {(time.time() - start_time):.1f}s''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
