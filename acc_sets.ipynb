{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceleration Data Processor (Sets)\n",
    "\n",
    "## How to use\n",
    "1. Make sure all the required packages are installed\n",
    "    * Run the following command to install if you haven't: ```pip install pandas matplotlib scipy openpyxl notebook```\n",
    "2. If you are seeing this, you are already running jupyter notebook\n",
    "3. To run this program, navigate to:\n",
    "    1. Menu Bar >\n",
    "    2. Kernel >\n",
    "    3. Restart & Run All\n",
    "4. Follow the prompts at the bottom of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "import math\n",
    "import csv\n",
    "import os.path\n",
    "import glob\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "from aux_fn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data Conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converts CSV to Excel Workbook Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvToExcel(d, output_path, is_ms):\n",
    "    '''\n",
    "    Input: A dictionary of .csv file names, title of file name\n",
    "    Output: Data imported into excel workbook\n",
    "    '''\n",
    "    \n",
    "    # Create new Excel workbook\n",
    "    wb = openpyxl.Workbook()\n",
    "    # Just to remove the spare sheet\n",
    "    wb.remove(wb.active)\n",
    "    # Get the column ids where the required data is located from the user\n",
    "    startIndex, interval, column_ids = getInputForColumns()\n",
    "    excel_wb_name = \"working-merged\"\n",
    "\n",
    "    # Transform the user input in A1 format into index for use later\n",
    "    # [0: Time-stamp, 1: Acceleration X, 2: Acceleration Y, 3: Acceleration Z]\n",
    "    column_indexes = [a1ToIndex(colID, True) for colID in column_ids]\n",
    "\n",
    "    \n",
    "    # For each key in dictionary\n",
    "    for i, key in enumerate(d):\n",
    "        # Concatenate csv files which start and end at same point together\n",
    "        df_list = []\n",
    "        for file in d[key]:\n",
    "            formatted_output_path = output_path + \"/\" + file + \"-formatted.csv\"\n",
    "\n",
    "            # Creates a clean csv file for output\n",
    "            with open(formatted_output_path,\"w\",newline='') as f:\n",
    "                with open(f'{file}.csv') as my_file:\n",
    "            \n",
    "                    # Sets this as csv\n",
    "                    reader = csv.reader(my_file)\n",
    "                    formatted_csv = csv.writer(f)\n",
    "\n",
    "                    # Create a header in formatted.\n",
    "                    header = ['TimeStamp','TimeElapsed','Category','Acc-X','Acc-Y','Acc-Z']\n",
    "                    formatted_csv.writerow(header)\n",
    "\n",
    "                    # Start filtering\n",
    "                    i = 0 #initial value for the index, used for mapping\n",
    "                    for item in reader:                        \n",
    "                        if ((i-startIndex) >= 0) & (((i - startIndex) % interval) == 0):\n",
    "                            each_line = []\n",
    "                            for column_index in column_indexes:\n",
    "                                try:                                    \n",
    "                                    each_line.append(item[column_index])\n",
    "                                except:\n",
    "                                    pass # To prevent the code from stopping if some cells are blank\n",
    "                            each_line.insert(1,0)\n",
    "                            each_line.insert(2,'Acceleration')\n",
    "                            formatted_csv.writerow(each_line)\n",
    "                            i += 1\n",
    "                        else:\n",
    "                            i += 1\n",
    "                formatted_df = pd.read_csv(formatted_output_path,header = 0)\n",
    "                timeElapsed(formatted_df, is_ms)\n",
    "                #     Convert the respective files into a list of df\n",
    "                df_list.append(formatted_df)\n",
    "\n",
    "\n",
    "    #     Concatenate the dfs into 1\n",
    "        concat_df = pd.concat(df_list, axis = 1)\n",
    "\n",
    "    #     Create a new column: Average of all acceleration data\n",
    "        try:\n",
    "            concat_df['Average Y'] = concat_df['Acc-Y'].mean(axis=1)\n",
    "        except:\n",
    "    #         If only have 1 set of readings, still need to create a new column\n",
    "            concat_df['Average Y'] = concat_df['Acc-Y']\n",
    "      \n",
    "    #     Store key as title of file\n",
    "        title = key\n",
    "\n",
    "    #     Create ws with the title == key of dictionary\n",
    "        ws = wb.create_sheet(index=i, title=title)\n",
    "\n",
    "    #     Import the df into the excel sheet\n",
    "        for r in dataframe_to_rows(concat_df, index=False, header=True):\n",
    "            ws.append(r)\n",
    "\n",
    "    excel_wb_name = f\"{output_path}/{excel_wb_name}\"\n",
    "    wb.save(f'{excel_wb_name}.xlsx')\n",
    "    print(f\"Excel workbook created at {output_path}\")\n",
    "    return excel_wb_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) DataFrame Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to group csv files with the same start and destination together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortedDict(all_files):\n",
    "    '''\n",
    "    Input: Requires a list of .csv files\n",
    "    Output:\n",
    "    - A dictionary with values sorted according to the train trip\n",
    "    - file_names excluding '.csv'\n",
    "    \n",
    "    '''\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    # Retrieve file_names\n",
    "    file_names = ''.join(all_files).split('.csv')[:-1]\n",
    "\n",
    "\n",
    "    for name in file_names:\n",
    "\n",
    "    # If name of file has a digit, find index of digit\n",
    "        if hasNumbers(name):\n",
    "\n",
    "    # Find the index of the digit\n",
    "            idx = [char.isdigit() for char in name].index(True)\n",
    "\n",
    "    # Split by the index and store the front end as the key\n",
    "    # Note: '-1' is to exclude the whitespace as well\n",
    "            key = name[:idx-1]\n",
    "            if key in d:\n",
    "                d[key].append(name)\n",
    "            else:\n",
    "                d[key] = [name]\n",
    "        else:\n",
    "            if name in d:\n",
    "                d[name].append(name)\n",
    "            else:\n",
    "                d[name] = [name]\n",
    "\n",
    "    \n",
    "    return d, file_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to remove data for when train is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncateStationaryValues(df, Threshold, isInG):\n",
    "    # Currently using a rolling average n of 5. Hence the use of \"3\" as the start index in range.\n",
    "    # You can change the n to any odd number. If you choose \"3\", then the start index will be 1 and the end index will be 1.\n",
    "    # Future enhancements: Automate this functionality\n",
    "    \n",
    "    threshold = Threshold # Threshold is assigned here. Typically 0.02 if values are in m/s^2\n",
    "    \n",
    "    from copy import deepcopy\n",
    "    \n",
    "    acc_data = deepcopy(df.loc[:, \"Average Y\"].tolist())\n",
    "        \n",
    "    if (isInG):\n",
    "        for i, e in enumerate(acc_data):\n",
    "            acc_data[i] = -e*9.81\n",
    "    else:\n",
    "        for i, e in enumerate(acc_data):\n",
    "            acc_data[i] = -e\n",
    "    \n",
    "    j = 3\n",
    "    rolling_avg_prev = (acc_data[j-2] + acc_data[j-1] + acc_data[j] + acc_data[j+1] + acc_data[j+2])/5\n",
    "    rolling_avg_cur = 0\n",
    "    truncate_index = 0\n",
    "    \n",
    "    for i in range(3, len(df) - 3):\n",
    "        rolling_avg_cur = (acc_data[i-2] + acc_data[i-1] + acc_data[i] + acc_data[i+1] + acc_data[i+2])/5\n",
    "        delta = rolling_avg_cur - rolling_avg_prev\n",
    "        if (delta > threshold):\n",
    "            # print(i, delta, acc_data[i]) # For debugging\n",
    "            truncate_index = i\n",
    "            break\n",
    "    \n",
    "    rowsToTruncate = [idx for idx in range(1, truncate_index)]\n",
    "    df = df.drop(rowsToTruncate)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Generate Time Elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeElapsed(df, is_ms): \n",
    "    \n",
    "    # Calculate and write a time_elapsed column\n",
    "    df[\"TimeElapsed\"] = df[\"TimeStamp\"] - df[\"TimeStamp\"].iloc[0]\n",
    "    \n",
    "    if is_ms == \"y\":\n",
    "        df[\"TimeElapsed\"] = df[\"TimeElapsed\"] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Generate Time Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveLongestTimeCol(df, col):\n",
    "    '''\n",
    "    To retrieve the col inputted with the MOST number of rows\n",
    "    '''\n",
    "    \n",
    "# Remove all rows where all values are blank then Retrieve the last value    \n",
    "    last_value_of_t = df[col].dropna(how=\"all\").iloc[-1]\n",
    "    t = df[col].dropna(how=\"all\").reset_index(drop=True) # Shift the index back to 0!\n",
    "\n",
    "# If there's only 1 \"Timestamp\" in the excel sheet, then our x-axis will just equal to it. 'pass' because values assigned to t already is correct\n",
    "    if type(last_value_of_t) == float or type(last_value_of_t) == int:\n",
    "        pass\n",
    "    else:\n",
    "# Retrieve index of time that is not 'NaN'. This is equivalent to retrieving maximum time (I.e. Most number of rows)\n",
    "        time_formatted = [i for i, el in enumerate(list(t.iloc[-1])) if not math.isnan(el)]\n",
    "        idx = time_formatted[0] # This works because there should only be 1 value that is 'NaN' \n",
    "\n",
    "# t = Col with most number of rows\n",
    "        t = t.iloc[:, idx]\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeInterval(df):\n",
    "    '''calculate time interval from the TimeElpased column'''\n",
    "    t = retrieveLongestTimeCol(df, col = \"TimeElapsed\")\n",
    "    \n",
    "    # Retrieve all rows excluding last & reset the index (Shift it back down to 0)\n",
    "    next_value = t.iloc[1:].reset_index(drop=True)\n",
    "    # Find difference\n",
    "    timeInterval = next_value - t\n",
    "    # Add '0' value to first row & Format the index again\n",
    "    timeInterval = pd.concat([pd.Series([0]), timeInterval]).reset_index(drop = True)\n",
    "    # Apparently, df[\"TimeInterval\"] values start from 1, hence the need for the code below\n",
    "    timeInterval.index = range(1,len(timeInterval)+1)\n",
    "    \n",
    "    df[\"TimeInterval\"] = timeInterval\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate Acc-Y-Adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accAdjust(df, smoothen_curve, format_acc):\n",
    "    '''Generate the Acc-Y-Adjusted and take the shift value into account'''\n",
    "    \n",
    "    #index of Acc-Y-Adjusted: 7\n",
    "\n",
    "    if format_acc == 'y':\n",
    "        df[\"Average Y\"] = df[\"Average Y\"] * -9.81\n",
    "    acc_Y = df[\"Average Y\"]\n",
    "#     for i in range(len(df)):\n",
    "#         acc_Y.append(df.iloc[i,4]*9.8)\n",
    "        \n",
    "    # Filter to remove noise\n",
    "    n = int(smoothen_curve)  # the larger n is, the smoother the curve will be\n",
    "    b = [1.0 / n] * n # b, numerator coefficient vector in a 1-D sequence\n",
    "    a = 1 # a, denominator coefficient vector in a 1-D sequence\n",
    "    acc_Y_filtered = lfilter(b,a,acc_Y)\n",
    "        \n",
    "    df[\"Acc-Y-Adjusted\"] = acc_Y_filtered\n",
    "    \n",
    "    #shift value\n",
    "    shift_value = df[\"Acc-Y-Adjusted\"].mean()\n",
    "    df[\"Acc-Y-Adjusted\"] = df[\"Acc-Y-Adjusted\"] - shift_value\n",
    "#     for i in range(len(df)):\n",
    "#         df.iloc[i,7] = df.iloc[i,7] - shift_value\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate V-btw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dv(df):\n",
    "    '''Generate the d_v using the definition of integration using the Acc-Y-Adjusted values'''\n",
    "    \n",
    "    d_v = 0.5 * (df[\"Acc-Y-Adjusted\"].iloc[1:].reset_index(drop=True) + df[\"Acc-Y-Adjusted\"]) * df[\"TimeInterval\"]\n",
    "    \n",
    "    df[\"V-btw2\"] = d_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate V(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vt(df):\n",
    "    '''Generate the v(t) column to record the instantaneous velocity of all data points'''\n",
    "    \n",
    "    false_list = [0]*len(df)\n",
    "    df[\"V(t)\"] = false_list\n",
    "    ins_v = [0]\n",
    "    for i in range(1,len(df)):\n",
    "    # index8: V-btw2\n",
    "        ins_v.append(sum(df[\"V-btw2\"].iloc[:i-1]))\n",
    "    df[\"V(t)\"] = ins_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate S-btw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds(df):\n",
    "    '''Generate the d_s using the definition of integration using the V(t) values'''\n",
    "    \n",
    "    d_s = 0.5 * (df[\"V(t)\"].iloc[1:].reset_index(drop=True) + df[\"V(t)\"]) * df[\"TimeInterval\"]\n",
    "    \n",
    "    df[\"S-btw2\"] = d_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate S(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st(df):\n",
    "    '''Generate the s(t) column to record the instantaneous displacement of all data points'''\n",
    "    \n",
    "    false_list = [0]*len(df)\n",
    "    df[\"S(t)\"] = false_list  \n",
    "    \n",
    "    ins_s = [0]\n",
    "    for i in range(1,len(df)):\n",
    "        ins_s.append(sum(df[\"S-btw2\"].iloc[:i-1]))\n",
    "\n",
    "    df[\"S(t)\"] = ins_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to integrate all the functions in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatHeaders(df):\n",
    "    \n",
    "# Format headers as long as the first row is not a numerical value\n",
    "# Note: Headers are not considered as the first row\n",
    "# Note: '.item()' is to convert numpy types to native Python types\n",
    "    try:\n",
    "        if type(df.iloc[0, 0].item()) == float:\n",
    "            pass\n",
    "    except:\n",
    "        header = df.iloc[0]\n",
    "        df = df[1:]\n",
    "        df.columns = header\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfFormat(df, smoothen_curve, format_acc, dfFormatArgs):\n",
    "    df = formatHeaders(df)\n",
    "    \n",
    "    timeInterval(df)\n",
    "    \n",
    "    df = truncateStationaryValues(df, dfFormatArgs[\"Threshold\"], dfFormatArgs[\"isInG\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    accAdjust(df, smoothen_curve, format_acc)\n",
    "    dv(df)\n",
    "    vt(df)\n",
    "    ds(df)\n",
    "    st(df)\n",
    "#     print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Physical Property Determination (Data Insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Distance Travelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(df):\n",
    "    '''Get the total distance travelled'''\n",
    "    \n",
    "    Total_Distance_Travelled = max(df[\"S(t)\"])\n",
    "    \n",
    "    return Total_Distance_Travelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Time Taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalTime(df):\n",
    "    '''Get the total time taken'''\n",
    "    t = retrieveLongestTimeCol(df, col = \"TimeElapsed\")\n",
    "    Total_Time_Taken = t.iloc[-1]\n",
    "    \n",
    "    return Total_Time_Taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxVelocity(df):\n",
    "    '''Get the max velocity'''\n",
    "    \n",
    "    Max_Velocity = max(df[\"V(t)\"])\n",
    "    \n",
    "    return Max_Velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceleration Cut-off Time & Average Acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables: <br>\n",
    "negative_acc_list: A list of indexes for which the acceleration value is nagetive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aveAcc(df):\n",
    "    '''Get the cut-off time for acceleration & Average Acceleration'''\n",
    "    \n",
    "    # To avoid early cut-off set the threshhold to be 5% of total journey\n",
    "    cutoff_threshold = 0.05\n",
    "    \n",
    "    # A list of indexes for which the acceleration value is nagetive\n",
    "    negative_acc_list = df[df[\"Acc-Y-Adjusted\"] < 0].index.tolist()\n",
    "\n",
    "    while negative_acc_list[0] < cutoff_threshold*len(df):\n",
    "        negative_acc_list = negative_acc_list[1:]\n",
    "        \n",
    "    CutOff_Time = df.iloc[negative_acc_list[0],1]\n",
    "    \n",
    "    cutoff_idx = negative_acc_list[0]\n",
    "    acc_list = []\n",
    "    for i in range(cutoff_idx):\n",
    "        acc_list.append(df[\"Acc-Y-Adjusted\"].iloc[i])\n",
    "    Average_Acceleration = sum(acc_list)/len(acc_list)\n",
    "    \n",
    "    return CutOff_Time, Average_Acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxAcc(df):\n",
    "    '''Get the Maximum Acceleration'''\n",
    "    \n",
    "    Max_Acceleration = max(df[\"Acc-Y-Adjusted\"])\n",
    "\n",
    "    return Max_Acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to apply all the functions in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataInsights(df):\n",
    "    '''\n",
    "    Used to get all data insights in one function\n",
    "    '''\n",
    "    \n",
    "    totalDistTravelled = distance(df)\n",
    "    totalTimeTaken = totalTime(df)\n",
    "    maxV = maxVelocity(df)\n",
    "    cutOffTime, aveA = aveAcc(df)\n",
    "    maxA = maxAcc(df)\n",
    "    data = {\"d\": totalDistTravelled, \"totalT\": totalTimeTaken, \"maxV\": maxV, \"cutOffT\": cutOffTime, \"aveA\": aveA, \"maxA\": maxA}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Generating and Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDataInsights(data, title, output_path):\n",
    "    '''\n",
    "    Input: Dictionary of data generated from data(df)\n",
    "    Output: A .txt file located under specified_output_path/{title_of_csv_file}-insights with all insights generated\n",
    "    '''\n",
    "    \n",
    "    result_data = f'''\n",
    "    # Total distance travelled: {data[\"d\"]} m\n",
    "    # Total time taken (For multiple readings, it is the longest time): {data[\"totalT\"]} s\n",
    "    # Max velocity: {data[\"maxV\"]} m/s\n",
    "    # Cut-off time for acceleration: {data[\"cutOffT\"]} s\n",
    "    # Average acceleration: {data[\"aveA\"]} m/s^2\n",
    "    # Max acceleration: {data[\"maxA\"]} m/s^2\n",
    "    '''\n",
    "    \n",
    "    # Save Data Insights to File\n",
    "    formatted_output_path = output_path + \"/\" + title + \"-insights.txt\"\n",
    "    insights_file = open(formatted_output_path,\"w\",newline='')\n",
    "    insights_file.write(result_data)\n",
    "    insights_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAndSaveGraphs(df, title, data, output_path):\n",
    "    # Plot A/t\n",
    "    args_at = {\"title\": title, \"type\": \"Acceleration\", \"xlabel\": \"time (s)\", \"ylabel\": \"Y-Axis Acceleration (m/s^2)\", \"xcoldata\": \"TimeElapsed\", \"ycoldata\": \"Acc-Y-Adjusted\", \"indicatorName\": \"Acceleration Cut-off\", \"indicatorData\": data[\"cutOffT\"], \"path\": output_path}\n",
    "    plotAndSave(df, args_at)\n",
    "    \n",
    "    # Plot & Save V/t\n",
    "    args_vt = {\"title\": title, \"type\": \"Velocity\", \"xlabel\": \"time (s)\", \"ylabel\": \"Velocity (m/s)\", \"xcoldata\": \"TimeElapsed\", \"ycoldata\": \"V(t)\", \"indicatorName\": \"Max Velocity\", \"indicatorData\": data[\"maxV\"], \"path\": output_path}\n",
    "    plotAndSave(df, args_vt)\n",
    "    \n",
    "    # Plot & Save S/t\n",
    "    args_st = {\"title\": title, \"type\": \"Displacement\", \"xlabel\": \"time (s)\", \"ylabel\": \"Displacement (m)\", \"xcoldata\": \"TimeElapsed\", \"ycoldata\": \"S(t)\", \"indicatorName\": \"Total Distance Travelled\", \"indicatorData\": data[\"d\"], \"path\": output_path}\n",
    "    plotAndSave(df, args_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Prompt user for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userInput(): \n",
    "     # i.e. \"Output-1\"\n",
    "    output_dir = \"/\" + input(\"Please input the relative path ending with the desired folder name for output: \") \n",
    "    user_dir = input(\"Please input the relative path to the directory containing a single set of .csv files: \")\n",
    "    while True:\n",
    "        try:                \n",
    "            smoothen_curve = input(\"Enter the step value for smoothing [1 - 15]\\n\\t The higher the value, the smoother it is: \")\n",
    "            if int(smoothen_curve) in range(1,16):\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "            format_acc = input(\"Is your acceleration measured in g? (I.e. '1' represents 9.81ms^-2) [Y]/[N]: \").lower()\n",
    "\n",
    "            if format_acc == 'y' or format_acc == 'n':\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "            is_ms = input(\"Is your time measured in ms? (I.e. '1000' represents 1s) [Y]/[N]: \").lower()\n",
    "            if is_ms == 'y' or is_ms == 'n':\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "            threshold = float(input(\"Enter the threshold value for automatic start point truncation [0 - 1]\\n\\t Typically 0.02: \"))\n",
    "            break\n",
    "        except:\n",
    "            print(\"Invalid Input. Please try again.\")\n",
    "            continue\n",
    "            \n",
    "    return output_dir, user_dir, smoothen_curve, format_acc, is_ms, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it all (Main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Get user input\n",
    "    output_dir, user_dir, smoothen_curve, format_acc, is_ms, threshold = userInput()\n",
    "\n",
    "    # Setup Output Path\n",
    "    my_path = os.path.realpath(\"\")\n",
    "    output_path = my_path + output_dir\n",
    "    mkdir_p(output_path)\n",
    "    \n",
    "    # Create new Excel workbook\n",
    "    wb = openpyxl.Workbook()\n",
    "    # Just to remove the spare sheet\n",
    "    wb.remove(wb.active)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Retrieve directory containing all .csv files\n",
    "    path = \"c:\\\\\"\n",
    "    extension = \"csv\"\n",
    "    os.chdir(user_dir)\n",
    "    all_files = glob.glob(f\"*.{extension}\")\n",
    "    d, file_names = sortedDict(all_files)\n",
    "      \n",
    "    print(f\"Results will be available at: {output_path}\")\n",
    "\n",
    "\n",
    "    # Reads sorted dict of csv files. Converts them to data frame and concatenate similar ones together. Outputs excel wb\n",
    "    excel_wb_name = csvToExcel(d, output_path, is_ms)\n",
    "    \n",
    "    # Change back to original directory\n",
    "    os.chdir(my_path)\n",
    "    \n",
    "    acceleration_data = pd.read_excel(f\"{excel_wb_name}.xlsx\", sheet_name=None, header=None)\n",
    "\n",
    "    for i, title in enumerate(acceleration_data):\n",
    "        print(f\"Status: Running {i+1} / {len(acceleration_data)}\")\n",
    "        df = acceleration_data[title]\n",
    "        \n",
    "        isInG = (format_acc == \"y\")\n",
    "        dfFormatArgs = {\"Threshold\": threshold, \"isInG\": isInG}\n",
    "        # Calculations to get the adjusted acceleration, velocity, and displacement\n",
    "        df = dfFormat(df, smoothen_curve, format_acc, dfFormatArgs) \n",
    "\n",
    "        # Save the DataFrame as the csv file\n",
    "        formatted_csv_path = output_path + \"/\" + title + \"-formatted.csv\"\n",
    "        df.to_csv(formatted_csv_path)\n",
    "        \n",
    "        # Get data insights\n",
    "        data = getDataInsights(df)\n",
    "        \n",
    "        # Save the insights into a .txt file\n",
    "        saveDataInsights(data, title, output_path)\n",
    "        \n",
    "        # Plot & save data to specified output location\n",
    "        plotAndSaveGraphs(df, title, data, output_path)\n",
    "\n",
    "        print(\"Program has finished running!\")\n",
    "        print(\"Results will be available at: {}\".format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
