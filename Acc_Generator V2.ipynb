{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Test) Finding required time-shift using cross-correlation\n",
    "Programmed by: Elvis\n",
    "\n",
    "This will find the best time-shift in order to get the same start and end points between two sets of data with one being the main set to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceleration Data Processor Version 2.0\n",
    "Programed by: Sean, Yijia, Elvis\n",
    "\n",
    "## How to use\n",
    "1. Make sure all the required packages are installed\n",
    "    * Run the following command to install if you haven't: ```pip install pandas matplotlib xlrd scipy notebook```\n",
    "2. If you are seeing this, you are already running jupyter notebook\n",
    "3. To run this program, navigate to:\n",
    "    1. Menu Bar >\n",
    "    2. Kernel >\n",
    "    3. Restart & Run All\n",
    "4. Follow the prompts at the bottom of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import lfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Formatting the specified raw data provided in .csv format "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```getInputForColumns()```\n",
    "Returns a list with column ids as Strings.\n",
    "    \n",
    "The elements are column ids in A1 format and are set as follows:\\\n",
    "[Time-stamp, Acceleration X, Acceleration Y, Accelerationz]\n",
    "\n",
    "Function parameters:\\\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputForColumns():\n",
    "    \"\"\"Returns a list with column ids as Strings.\n",
    "    \n",
    "    The elements are column ids in A1 format and are set as follows:\n",
    "    [Time-stamp, Acceleration X, Acceleration Y, Acceleration Z]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get input for the columns\n",
    "    column_ids = [\"\", \"\", \"\", \"\"]\n",
    "    buffer = \"\"\n",
    "    isFinal = False\n",
    "    \n",
    "    while (isFinal == False):\n",
    "        print(\"Enter the Column ID in A1 format (e.g. A, B, C) for the following items:\")\n",
    "        buffer = input(\"Time-stamp: \")\n",
    "        column_ids[0] = buffer\n",
    "        buffer = input(\"Acceleration X: \")\n",
    "        column_ids[1] = buffer\n",
    "        buffer = input(\"Acceleration Y: \")\n",
    "        column_ids[2] = buffer\n",
    "        buffer = input(\"Acceleration Z: \")\n",
    "        column_ids[3] = buffer\n",
    "        buffer = input(\"Confirm entry? [Y]/[N]: \")\n",
    "        if (buffer.lower() == \"y\"):\n",
    "            isFinal = True\n",
    "    \n",
    "    return column_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```a1ToIndex```\n",
    "Converts the Supplied Column ID in A1 format to a Normal Index starting from 0\n",
    "    \n",
    "Function parameters:\\\n",
    "(String) a1 -- Column ID in String Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def a1ToIndex(a1, isZeroIndex):\n",
    "    \"\"\"Converts the Supplied Column ID in A1 format to a Normal Index starting from 0\n",
    "    \n",
    "    Function parameters:\n",
    "    (String) a1 -- Column ID in String Format\n",
    "    \"\"\"\n",
    "    assert type(a1) is str, \"Expected a String\"\n",
    "    assert type(isZeroIndex) is bool, \"Expected a Boolean\"\n",
    "    from openpyxl.utils import column_index_from_string\n",
    "    return column_index_from_string(a1) - int(isZeroIndex)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters, Creates new csv, and Converts to Pandas Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**Parameter**|**Description**|**Variable Used**|**Description**|\n",
    "|:-|:-|:-|:-|\n",
    "|```file_name```|the name of the file (in string)|```formatted```|the csv file generated and one where filtering is applied to|\n",
    "|```title```|name of the file|```df```|the DataFrame generated from the formatted csv file|\n",
    "|```output_path```|the path for output| |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2df(file_name, title, output_path):\n",
    "    '''filter the csv file & import to DataFrame'''\n",
    "    formatted_output_path = output_path + \"/\" + title + \"-formatted.csv\"\n",
    "    \n",
    "    # Get the column ids where the required data is located from the user\n",
    "    column_ids = getInputForColumns()\n",
    "    # Transform the user input in A1 format into index for use later\n",
    "    # [0: Time-stamp, 1: Acceleration X, 2: Acceleration Y, 3: Acceleration Z]\n",
    "    column_indexes = [a1ToIndex(colID, True) for colID in column_ids]\n",
    "    \n",
    "    # Opens the given file\n",
    "    my_file = open(file_name)\n",
    "    \n",
    "    # Creates a clean csv file for output\n",
    "    formatted = open(formatted_output_path,\"w\",newline='')\n",
    "    \n",
    "    # Sets this as csv\n",
    "    reader = csv.reader(my_file)\n",
    "    formatted_csv = csv.writer(formatted)\n",
    "    \n",
    "    # Create a header in formatted.\n",
    "    header = ['TimeStamp','TimeElapsed','Category','Acc-X','Acc-Y','Acc-Z']\n",
    "    formatted_csv.writerow(header)\n",
    "    \n",
    "    # Start filtering\n",
    "    for item in reader:\n",
    "        if item[1] == 'acc':\n",
    "            each_line = list(item)\n",
    "            # Create a column for \"TimeElapsed\" later\n",
    "            each_line.insert(1,0)\n",
    "            formatted_csv.writerow(each_line)\n",
    "    \n",
    "    # Closes the given file\n",
    "    my_file.close()\n",
    "    \n",
    "    # Change to Dataframe in pandas\n",
    "    df = pd.read_csv(formatted_output_path,header = 0)   \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) DataFrame Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Generate Time Elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeElapsed(df): \n",
    "    # Calculate and write a time_elapsed column\n",
    "    startTime = df.iloc[0,0]\n",
    "    for i in range(len(df)):\n",
    "        df.iloc[i,1]=(df.iloc[i,0]-startTime)/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Generate Time Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeInterval(df):\n",
    "    '''calculate time interval from the TimeElpased colomn'''\n",
    "    \n",
    "    #index of TimeInterval: 6\n",
    "    timeInterval = [0]\n",
    "    for i in range (1,len(df)):\n",
    "        timeInterval.append(df.iloc[i,1]-df.iloc[i-1,1])\n",
    "        \n",
    "    df[\"TimeInterval\"]=timeInterval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate Acc-Y-Adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable: <br>\n",
    "shift_value: the value to shift all acceleration values \n",
    "<p> in this application, the shift value from the experiment results, is approximately to be (initial accelration)/2</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accAdjust(df):\n",
    "    '''Generate the Acc-Y-Adjusted and take the shift value into account'''\n",
    "    \n",
    "    #index of Acc-Y-Adjusted: 7\n",
    "    acc_Y = []\n",
    "    for i in range(len(df)):\n",
    "        acc_Y.append(-df.iloc[i,4]*9.8)\n",
    "        \n",
    "    # Filter to remove noise\n",
    "    n = 15  # the larger n is, the smoother curve will be\n",
    "    b = [1.0 / n] * n # b, numerator coefficient vector in a 1-D sequence\n",
    "    a = 1 # a, denominator coefficient vector in a 1-D sequence\n",
    "    acc_Y_filtered = lfilter(b,a,acc_Y)\n",
    "        \n",
    "    df[\"Acc-Y-Adjusted\"] = acc_Y_filtered\n",
    "    \n",
    "    #shift value\n",
    "    shift_value = df.iloc[0,7]/2\n",
    "    for i in range(len(df)):\n",
    "        df.iloc[i,7] = df.iloc[i,7] - shift_value\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate V-btw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dv(df):\n",
    "    '''Generate the d_v using the definition of integration using the Acc-Y-Adjusted values'''\n",
    "    \n",
    "    #index of V-btw2: 8\n",
    "    d_v = [0]\n",
    "    for i in range (1,len(df)):\n",
    "        velocity_each = 0.5*(df.iloc[i,7]+df.iloc[i-1,7])*df.iloc[i,6] #index7: Acc-Y-Adjusted, index6: TimeInterval\n",
    "        d_v.append(velocity_each)\n",
    "    \n",
    "    df[\"V-btw2\"]=d_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate V(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vt(df):\n",
    "    '''Generate the v(t) colomn to record the instantanious velocity in any data point'''\n",
    "    \n",
    "    #index of V(t): 9\n",
    "    false_list = [0]*len(df)\n",
    "    df[\"V(t)\"] = false_list\n",
    "    \n",
    "    for i in range(1,len(df)):\n",
    "    # index8: V-btw2\n",
    "        ins_v = df.iloc[i,8]+df.iloc[i-1,9]\n",
    "        df.iloc[i,9] = ins_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate S-btw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds(df):\n",
    "    '''Generate the d_s using the definition of integration using the V(t) values'''\n",
    "    \n",
    "    #index of S-btw2: 10\n",
    "    d_s = [0]\n",
    "    for i in range (1,len(df)):\n",
    "        # index9: v(t), index6: TimeInterval\n",
    "        displacement_each = 0.5*(df.iloc[i,9]+df.iloc[i-1,9])*df.iloc[i,6]\n",
    "        d_s.append(displacement_each)\n",
    "        \n",
    "    df[\"S-btw2\"] = d_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate S(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st(df):\n",
    "    '''Generate the s(t) colomn to record the instantanious displacement in any data point'''\n",
    "    \n",
    "    #index of V(t): 11\n",
    "    false_list = [0]*len(df)\n",
    "    df[\"S(t)\"] = false_list\n",
    "    \n",
    "    for i in range(1,len(df)):\n",
    "        # index10: S-btw2\n",
    "        ins_v = df.iloc[i,10]+df.iloc[i-1,11]\n",
    "        df.iloc[i,11] = ins_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to integrate all the functions in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfFormat(df):\n",
    "    timeElapsed(df)\n",
    "    timeInterval(df)\n",
    "    accAdjust(df)\n",
    "    dv(df)\n",
    "    vt(df)\n",
    "    ds(df)\n",
    "    st(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Physical Property Determination (Data Insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Distance Travelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(df):\n",
    "    '''Get the total distance travelled'''\n",
    "    \n",
    "    Total_Distance_Travelled = max(df[\"S(t)\"])\n",
    "    \n",
    "    return Total_Distance_Travelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Time Taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalTime(df):\n",
    "    '''Get the total time taken'''\n",
    "    \n",
    "    Total_Time_Taken = df.iloc[len(df)-1,1]\n",
    "    \n",
    "    return Total_Time_Taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxVelocity(df):\n",
    "    '''Get the max velocity'''\n",
    "    \n",
    "    Max_Velocity = max(df[\"V(t)\"])\n",
    "    \n",
    "    return Max_Velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceleration Cut-off Time & Average Acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables: <br>\n",
    "negative_acc_list: a list of the index of which the acceleration value is nagetive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(df):\n",
    "    '''Get the cut-off time for acceleration & Average Acceleration'''\n",
    "    \n",
    "    negative_acc_list = df[df[\"Acc-Y-Adjusted\"] < 0].index.tolist()\n",
    "    # To avoid early cut-off\n",
    "    # set the threshhold to be 1/4 of total journey\n",
    "    while negative_acc_list[0] < 0.25*len(df):\n",
    "        negative_acc_list = negative_acc_list[1:]\n",
    "        \n",
    "    CutOff_Time = df.iloc[negative_acc_list[0],1]\n",
    "    \n",
    "    cutoff_idx = negative_acc_list[0]\n",
    "    acc_list = []\n",
    "    for i in range(cutoff_idx):\n",
    "        acc_list.append(df.iloc[i,7])\n",
    "    Average_Acceleration = sum(acc_list)/len(acc_list)\n",
    "    \n",
    "    return CutOff_Time, Average_Acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxAcc(df):\n",
    "    '''Get the maxium Acceleration'''\n",
    "    \n",
    "    Max_Acceleration = max(df[\"Acc-Y-Adjusted\"])\n",
    "\n",
    "    return Max_Acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to integrate all the functions in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(df):\n",
    "    Total_Distance_Travelled = distance(df)\n",
    "    Total_Time_Taken = totalTime(df)\n",
    "    Max_Velocity = maxVelocity(df)\n",
    "    CutOff_Time, Average_Acceleration = acc(df)\n",
    "    Max_Acceleration = maxAcc(df)\n",
    "    \n",
    "    result_data = f'''\n",
    "    # Total distance travelled: {Total_Distance_Travelled} m\n",
    "    # Total time taken: {Total_Time_Taken} s\n",
    "    # Max velocity: {Max_Velocity} m/s\n",
    "    # Cut-off time for acceleration: {CutOff_Time} s\n",
    "    # Average acceleration: {Average_Acceleration} m/s^2\n",
    "    # Max acceleration: {Max_Acceleration} m/s^2\n",
    "    '''\n",
    "    \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Generating and Saving Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph a-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAcc(df,title,CutOff_Time, output_path):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "    axes.set_xlabel('time (s)')\n",
    "    axes.set_ylabel('Acceleration_y (m/s^2)', color='tab:blue')\n",
    "    \n",
    "    t=df[\"TimeElapsed\"]\n",
    "    acc_y=df[\"Acc-Y-Adjusted\"]\n",
    "    axes.plot(t,acc_y,color=\"red\", lw=2, ls='-')\n",
    "    axes.axvline(CutOff_Time, 0, 1, label='Cut-off for acceleration')\n",
    "    axes.axhline(0, color='black')\n",
    "    axes.legend()\n",
    "    axes.title.set_text(title)\n",
    "    \n",
    "    name = title + '-'+ 'Acceleration'\n",
    "    plt.savefig(f'{output_path}/{name}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph v-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotVelocity(df,title,Max_Velocity, output_path):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "    axes.set_xlabel('time (s)')\n",
    "    axes.set_ylabel('Velocity (m/s)', color='tab:blue')\n",
    "    \n",
    "    t=df[\"TimeElapsed\"]\n",
    "    v=df[\"V(t)\"]\n",
    "    axes.plot(t,v,color=\"red\", lw=2, ls='-')\n",
    "    axes.axhline(Max_Velocity, 0, 1, label='Max Velocity')\n",
    "    axes.legend()\n",
    "    axes.title.set_text(title)\n",
    "    \n",
    "    name = title + '-'+ 'Velocity'\n",
    "    plt.savefig(f'{output_path}/{name}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph s-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDisplacement(df,title,Total_Distance_Travelled, output_path):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "    axes.set_xlabel('time (s)')\n",
    "    axes.set_ylabel('Displacement (m)', color='tab:blue')\n",
    "    \n",
    "    t=df[\"TimeElapsed\"]\n",
    "    s=df[\"S(t)\"]\n",
    "    axes.plot(t,s,color=\"red\", lw=2, ls='-')\n",
    "    axes.axhline(Total_Distance_Travelled, 0, 1, label='Total Distance Travelled')\n",
    "    axes.legend()\n",
    "    axes.title.set_text(title)\n",
    "    \n",
    "    name = title + '-'+ 'Displacement'\n",
    "    plt.savefig(f'{output_path}/{name}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Calculating and Generating Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(mypath):\n",
    "    '''Creates a directory. equivalent to using mkdir -p on the command line'''\n",
    "\n",
    "    from errno import EEXIST\n",
    "    from os import makedirs,path\n",
    "\n",
    "    try:\n",
    "        makedirs(mypath)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == EEXIST and path.isdir(mypath):\n",
    "            pass\n",
    "        else: raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it all (Main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # User Input\n",
    "    output_dir = \"/\" + input(\"Please input the folder name for output: \") # i.e. \"Output-1\"\n",
    "    file_name = input(\"Please input the relative path to csv file: \") # i.e. \"example_data/UC_EXPO_first.csv\"\n",
    "    \n",
    "    \n",
    "    # Setup Output Path\n",
    "    my_path = os.path.realpath(\"\")\n",
    "    output_path = my_path + output_dir\n",
    "    mkdir_p(output_path)\n",
    "    \n",
    "    print(\"Results will be available at: {}\".format(output_path))\n",
    "    \n",
    "    # Get the title of the file\n",
    "    title = file_name.split('.')[0]\n",
    "    if ('/' in title):\n",
    "        additionalSplit = title.split('/')\n",
    "        title = additionalSplit[len(additionalSplit) - 1]\n",
    "    \n",
    "    # Reads csv file. Saves the new formatted file and converts it into a pandas data frame\n",
    "    df = csv2df(file_name, title, output_path)\n",
    "    # Calculations to get the adjusted acceleration, velocity, and displacement\n",
    "    df = dfFormat(df) \n",
    "    df.to_csv(formatted_output_path)\n",
    "    \n",
    "    # Calculate Data Insights\n",
    "    result_data = data(df)\n",
    "    \n",
    "    # Save Data Insights to File\n",
    "    formatted_output_path = output_path + \"/\" + title + \"-insights.txt\"\n",
    "    insights_file = open(formatted_output_path,\"w\",newline='')\n",
    "    insights_file.write(result_data)\n",
    "    insights_file.close()\n",
    "    \n",
    "    # The next three lines are for use in plotting as parameters\n",
    "    Total_Distance_Travelled = distance(df)\n",
    "    Max_Velocity = maxVelocity(df)\n",
    "    CutOff_Time, Average_Acceleration = acc(df)\n",
    "    \n",
    "    # Plot & save data to specified output location\n",
    "    plotAcc(df,title, CutOff_Time, output_path)\n",
    "    plotVelocity(df, title, Max_Velocity, output_path)\n",
    "    plotDisplacement(df, title, Total_Distance_Travelled, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the folder name for output: output\n",
      "Please input the relative path to csv file: ../data/nsl-run1-1-amk-to-yck-elv.csv\n",
      "Results will be available at: /home/elviskasonlin/Code/projects/sutd-1d-physicalworld/python/output\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-e5eb69615056>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Reads csv file. Saves the new formatted file and converts it into a pandas data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv2df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Calculations to get the adjusted acceleration, velocity, and displacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-379d5818bf2a>\u001b[0m in \u001b[0;36mcsv2df\u001b[0;34m(file_name, title, output_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Change to Dataframe in pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_output_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/dtsc/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/dtsc/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/dtsc/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/dtsc/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/dtsc/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
